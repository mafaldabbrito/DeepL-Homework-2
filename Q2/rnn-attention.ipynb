{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14436578,"sourceType":"datasetVersion","datasetId":9221365}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# config\nfrom dataclasses import dataclass\n\n@dataclass\nclass RNAConfig:\n    \"\"\"Global configuration for the RNAcompete Data Pipeline.\"\"\"\n    \n    # Data Path\n    DATA_PATH: str = \"norm_data.txt\" #NOTE: Only change this if you want to use a different path\n    \n    # Metadata is an Excel file\n    METADATA_PATH: str = \"metadata.xlsx\" #NOTE: Only change this if you want to use a different path\n    METADATA_SHEET: str = \"Master List--Plasmid Info\"\n    \n    # Save Path\n    SAVE_DIR: str = \"data\" #NOTE: Only change this if you want to use a different path\n    \n    # Sequence Parameters\n    SEQ_MAX_LEN: int = 41\n    ALPHABET: str = \"ACGUN\"\n    \n    # Preprocessing\n    CLIP_PERCENTILE: float = 99.95\n    EPSILON: float = 1e-6  # For numerical stability\n    \n    # Split Identifiers\n    TRAIN_SPLIT_ID: str = \"SetA\"\n    TEST_SPLIT_ID: str = \"SetB\"\n    \n    VAL_SPLIT_PCT: float = 0.2\n    SEED: int = 42 # NOTE: Change this only if you want to test reproducibility","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T20:54:59.049988Z","iopub.execute_input":"2026-01-08T20:54:59.050629Z","iopub.status.idle":"2026-01-08T20:54:59.059001Z","shell.execute_reply.started":"2026-01-08T20:54:59.050599Z","shell.execute_reply":"2026-01-08T20:54:59.058319Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"## Utils\nimport os\nimport random\nimport sys\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom typing import List, Tuple\n\n\ndef configure_seed(seed):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\n\nclass RNACompeteLoader:\n    def __init__(self, config: RNAConfig):\n        \"\"\"\n        Initializes the loader.\n        \"\"\"\n        self.cfg = config\n        self.meta_df = None\n        self.data_df = None\n        self.protein_to_id = None\n\n        # Setup Encoding\n        self.char_map = {\n            'A': np.array([1, 0, 0, 0], dtype=np.float32),\n            'C': np.array([0, 1, 0, 0], dtype=np.float32),\n            'G': np.array([0, 0, 1, 0], dtype=np.float32),\n            'U': np.array([0, 0, 0, 1], dtype=np.float32),\n            'N': np.array([0.25, 0.25, 0.25, 0.25], dtype=np.float32)\n        }\n        self.padding_vec = np.zeros(4, dtype=np.float32)\n\n    def _ensure_data_loaded(self):\n        \"\"\"Helper to load the heavy files only when necessary.\"\"\"\n        if self.data_df is not None:\n            return\n        \n        # Load Metadata\n        print(f\"Loading Metadata from {self.cfg.METADATA_PATH}...\")\n        start_time = time.time()\n        try:\n            if self.cfg.METADATA_PATH.endswith('.xlsx'):\n                # Requires 'openpyxl' installed!\n                self.meta_df = pd.read_excel(\n                    self.cfg.METADATA_PATH, \n                    sheet_name=self.cfg.METADATA_SHEET\n                )\n            else:\n                self.meta_df = pd.read_csv(self.cfg.METADATA_PATH)\n        except Exception as e:\n            print(f\"Error loading metadata: {e}\")\n            raise e\n        print(f\"  > Metadata loaded in {time.time() - start_time:.2f} seconds.\")\n\n        # Clean column names (strip whitespace)\n        self.meta_df.columns = [c.strip() for c in self.meta_df.columns]\n        \n        # Create Protein Name -> RNCMPT ID mapping\n        self.protein_to_id = pd.Series(\n            self.meta_df['Motif_ID'].values, \n            index=self.meta_df['Protein_name']\n        ).to_dict()\n        \n        # Load Data \n        print(f\"Loading Data from {self.cfg.DATA_PATH}...\")\n        start_time = time.time()\n\n        # standard RNAcompete is tab-separated\n        self.data_df = pd.read_csv(self.cfg.DATA_PATH, sep='\\t', low_memory=False)    \n        print(f\"  > Data Matrix loaded in {time.time() - start_time:.2f} seconds.\")\n\n        # Clean data columns\n        self.data_df.columns = [c.strip() for c in self.data_df.columns]\n\n    def list_proteins(self) -> List[str]:\n        \"\"\"Returns a sorted list of available protein names.\"\"\"\n        self._ensure_data_loaded()\n        valid_proteins = []\n        matrix_cols = set(self.data_df.columns)\n        \n        for name, pid in self.protein_to_id.items():\n            if pid in matrix_cols:\n                valid_proteins.append(name)\n        \n        return sorted(valid_proteins)\n\n    def _encode_sequence(self, seq: str) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"One-hot encodes a single RNA sequence.\"\"\"\n        # Handle NaN or non-string sequence entries gracefully\n        if not isinstance(seq, str):\n            seq = \"N\" * self.cfg.SEQ_MAX_LEN\n        \n        seq = seq.upper()[:self.cfg.SEQ_MAX_LEN]\n        \n        encoded = np.zeros((self.cfg.SEQ_MAX_LEN, len(self.padding_vec)), dtype=np.float32)\n        mask = np.zeros(self.cfg.SEQ_MAX_LEN, dtype=np.float32)\n        \n        for i, base in enumerate(seq):\n            encoded[i] = self.char_map.get(base, self.char_map['N'])\n            mask[i] = 1.0\n        \n        return encoded, mask\n    \n    def _preprocess_intensities(self, intensities: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Applies: Mask NaNs -> Clip -> Log -> Z-score.\"\"\"\n        mask = (~np.isnan(intensities)).astype(np.float32)\n        clean_vals = np.nan_to_num(intensities, nan=0.0)\n        \n        # Clip\n        if np.sum(mask) > 0:\n            valid_data = intensities[mask == 1]\n            clip_val = np.percentile(valid_data, self.cfg.CLIP_PERCENTILE)\n            clean_vals = np.clip(clean_vals, None, clip_val)\n\n        # Log Transform (Shift to positive)\n        min_val = np.min(clean_vals)\n        shift = 0\n        if min_val <= 0:\n            shift = abs(min_val) + 1.0\n        clean_vals = np.log(clean_vals + shift + self.cfg.EPSILON)\n        \n        # Z-Score\n        masked_vals = clean_vals[mask == 1]\n        if len(masked_vals) > 0:\n            mean = np.mean(masked_vals)\n            std = np.std(masked_vals) + self.cfg.EPSILON\n            clean_vals = (clean_vals - mean) / std\n        \n        clean_vals = clean_vals * mask\n        return clean_vals, mask\n    \n    def get_data(self, protein_name: str, split: str = 'train') -> TensorDataset:\n        \"\"\"\n        Main method to get PyTorch Dataset for a specific protein.\n        \"\"\"\n        # Fast path: use preprocessed tensors if they are already available (e.g., Kaggle input dir)\n        kaggle_path = f\"/kaggle/input/rnacompete-dt/{protein_name}_{split}_data.pt\"\n        if os.path.exists(kaggle_path):\n            print(f\"Found preprocessed data at {kaggle_path}. Loading...\")\n            tensors = torch.load(kaggle_path, weights_only=False)\n            return TensorDataset(*tensors)\n\n        # Check cache first\n        os.makedirs(self.cfg.SAVE_DIR, exist_ok=True)\n        data_path = os.path.join(self.cfg.SAVE_DIR, f\"{protein_name}_{split}_data.pt\")\n\n        if os.path.exists(data_path):\n            print(f\"Found cached data for {protein_name} ({split}). Loading from {data_path}...\")\n            try:\n                tensors = torch.load(data_path, weights_only=False)\n                return TensorDataset(*tensors)\n            except Exception as e:\n                print(f\"Cache seems corrupted: {e}. Will reload from scratch.\")\n\n        self._ensure_data_loaded()\n\n        if protein_name not in self.protein_to_id:\n            raise ValueError(f\"Protein '{protein_name}' not found in metadata.\")\n        \n        rncmpt_id = self.protein_to_id[protein_name]\n        \n        if rncmpt_id not in self.data_df.columns:\n            raise ValueError(f\"ID {rncmpt_id} for {protein_name} missing from data matrix.\")\n\n        s_lower = split.lower()\n\n        if s_lower == 'test':\n            # Test set is just SetB, nice and simple\n            subset = self.data_df[self.data_df['Probe_Set'] == self.cfg.TEST_SPLIT_ID].copy()\n\n        elif s_lower in ['train', 'val']:\n            # For train/val, we need to split SetA. \n            # We use a fixed seed to ensure grading consistency (everyone gets the same split).\n            full_set = self.data_df[self.data_df['Probe_Set'] == self.cfg.TRAIN_SPLIT_ID]\n            \n            # Explicitly sort by index to ensure deterministic order before shuffling\n            full_set = full_set.sort_index()\n            \n            n_samples = len(full_set)\n            indices = np.arange(n_samples)\n            \n            # Local RandomState prevents messing with global seeds\n            rng = np.random.RandomState(self.cfg.SEED)\n            rng.shuffle(indices)\n            \n            val_size = int(n_samples * self.cfg.VAL_SPLIT_PCT)\n            \n            if s_lower == 'val':\n                # Validation gets the first chunk\n                subset_indices = indices[:val_size]\n            else:\n                # Train gets the leftovers\n                subset_indices = indices[val_size:]\n                \n            subset = full_set.iloc[subset_indices].copy()\n        else:\n            raise ValueError(f\"Unknown split '{split}'. Please use 'train', 'val', or 'test'.\")\n        \n        # Extract Sequences\n        raw_seqs = subset['RNA_Seq'].values\n        encoded_list = []\n        mask_list = []\n\n        for s in raw_seqs:\n            encoded, seq_mask = self._encode_sequence(s) \n            encoded_list.append(encoded)\n            mask_list.append(seq_mask)\n\n        X = np.stack(encoded_list)          # shape: (B, SEQ_MAX_LEN, 4)\n        sequence_masks = np.stack(mask_list)  # shape: (B, SEQ_MAX_LEN)\n\n        # Process Intensities\n        # Force conversion to numeric (floats), turning any strings/errors into NaN\n        raw_intensities = pd.to_numeric(subset[rncmpt_id], errors='coerce').values\n        Y, mask = self._preprocess_intensities(raw_intensities)\n        \n        # Convert to Tensor\n        dataset = TensorDataset(\n            torch.FloatTensor(X),                     # (B, 41, 4)\n            torch.FloatTensor(sequence_masks),        # (B, 41)\n            torch.FloatTensor(Y).unsqueeze(1),        # (B, 1)\n            torch.FloatTensor(mask).unsqueeze(1)      # (B, 1)\n        )\n        \n        # Save for next time\n        print(f\"Saving processed data to {data_path}...\")\n        torch.save(dataset.tensors, data_path)\n        \n        return dataset\n    \n\ndef load_rnacompete_data(protein_name: str, split: str = 'train', config: RNAConfig = None):\n    \"\"\"\n    Convenience function to load data for a single protein without manually managing the loader class.\n    Note: Instantiates the loader from scratch (loads files). \n    For bulk processing, use RNACompeteLoader class directly.\n    \"\"\"\n    if config is None:\n        config = RNAConfig()\n\n    loader = RNACompeteLoader(config)\n    return loader.get_data(protein_name, split)\n\n\ndef masked_spearman_correlation(preds, targets, masks):\n    \"\"\"\n    Calculates Spearman Rank Correlation on masked data.\n    Expects:\n        preds: (B, 1)\n        targets: (B, 1)\n        masks: (B, 1)\n    Outputs:\n        correlation: scalar\n    \"\"\"\n    # Flatten and detach (metrics don't need gradients)\n    preds = preds.squeeze().detach()\n    targets = targets.squeeze().detach()\n    masks = masks.squeeze().bool()\n    \n    valid_preds = preds[masks]\n    valid_targets = targets[masks]\n    \n    if valid_preds.numel() < 2:\n        return torch.tensor(0.0)\n\n    # argsort twice gets us the ranks\n    pred_ranks = valid_preds.argsort().argsort().float()\n    target_ranks = valid_targets.argsort().argsort().float()\n\n    # Pearson on ranks == Spearman\n    pred_mean = pred_ranks.mean()\n    target_mean = target_ranks.mean()\n\n    pred_var = pred_ranks - pred_mean\n    target_var = target_ranks - target_mean\n\n    correlation = (pred_var * target_var).sum() / torch.sqrt((pred_var ** 2).sum() * (target_var ** 2).sum())\n\n    return correlation\n\n\ndef masked_mse_loss(preds, targets, masks):\n    \"\"\"\n    Calculates Mean Squared Error, ignoring padded elements.\n    Expects:\n        preds: (B, 1)\n        targets: (B, 1)\n        masks: (B, 1)\n    Outputs:\n        loss: scalar\n    \"\"\"\n    # Flatten to 1D\n    preds = preds.squeeze()\n    targets = targets.squeeze()\n    masks = masks.squeeze().bool()\n\n    # Filter out padded values\n    masked_preds = preds[masks]\n    masked_targets = targets[masks]\n    \n    # Handle empty batch case\n    if masked_preds.numel() == 0:\n        return torch.tensor(0.0, device=preds.device, requires_grad=True)\n\n    # MSE on valid data\n    squared_error = (masked_preds - masked_targets) ** 2\n    loss = torch.mean(squared_error)\n    \n    return loss\n\n\ndef plot(epochs, plottables, filename=None, ylim=None):\n    \"\"\"Plot the plottables over the epochs.\n    \n    Plottables is a dictionary mapping labels to lists of values.\n    \"\"\"\n    plt.clf()\n    plt.xlabel('Epoch')\n    for label, plottable in plottables.items():\n        plt.plot(epochs, plottable, label=label)\n    plt.legend()\n    if ylim:\n        plt.ylim(ylim)\n    if filename:\n        plt.savefig(filename, bbox_inches='tight')\n\n\n# ---------------------------------------------------------------------------\n# Data exploration helpers\n# ---------------------------------------------------------------------------\n\ndef dataset_summary(dataset: TensorDataset) -> dict:\n    \"\"\"Return simple stats about a TensorDataset (X, y, mask).\"\"\"\n    X, y, mask = dataset.tensors\n    mask_bool = mask.squeeze().bool()\n\n    # Masked targets only\n    valid_targets = y.squeeze()[mask_bool]\n    valid_np = valid_targets.detach().cpu().numpy() if valid_targets.numel() else np.array([])\n\n    # Sequence lengths (after padding removal)\n    seq_lengths = (X.sum(dim=2) > 0).sum(dim=1).detach().cpu().numpy()\n\n    return {\n        \"num_samples\": int(X.shape[0]),\n        \"seq_min_len\": int(seq_lengths.min()) if len(seq_lengths) else 0,\n        \"seq_max_len\": int(seq_lengths.max()) if len(seq_lengths) else 0,\n        \"seq_mean_len\": float(seq_lengths.mean()) if len(seq_lengths) else 0.0,\n        \"mask_fraction\": float(mask_bool.float().mean().item()),\n        \"target_min\": float(valid_np.min()) if valid_np.size else 0.0,\n        \"target_max\": float(valid_np.max()) if valid_np.size else 0.0,\n        \"target_mean\": float(valid_np.mean()) if valid_np.size else 0.0,\n        \"target_std\": float(valid_np.std()) if valid_np.size else 0.0,\n    }\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T20:54:59.146138Z","iopub.execute_input":"2026-01-08T20:54:59.146850Z","iopub.status.idle":"2026-01-08T20:55:03.849124Z","shell.execute_reply.started":"2026-01-08T20:54:59.146813Z","shell.execute_reply":"2026-01-08T20:55:03.848511Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# RNN_attention\n\"\"\"\nCNN + BiLSTM model for RNAcompete binding prediction.\n\nMotifs are detected by a convolutional layer, and a bidirectional LSTM\nmodels upstream/downstream context before fully connected layers map\nfeatures to binding affinity.\n\"\"\"\n\nimport argparse\nimport json\nimport os\nimport time\nfrom typing import Dict, List, Tuple, Optional\nfrom argparse import Namespace\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\n\n# ============================================================================\n# Attention Pooling Module\n# ============================================================================\n\n\nclass AttentionPooling(nn.Module):\n\t\"\"\"\n\tScaled Dot-Product Attention Pooling Layer.\n\t\n\tComputes attention weights across all sequence positions and produces\n\ta weighted aggregation (pooling) into a single representation. This allows\n\tthe model to learn which positions are most informative for prediction.\n\t\n\tArgs:\n\t\thidden_dim: Dimension of input features (e.g., 2*lstm_hidden for BiLSTM)\n\t\tnum_heads: Number of attention heads for multi-head attention\n\t\"\"\"\n\n\tdef __init__(self, hidden_dim: int, num_heads: int = 2):\n\t\tsuper().__init__()\n\n\t\tself.hidden_dim = hidden_dim\n\t\tself.num_heads = num_heads\n\t\tself.head_dim = hidden_dim // num_heads\n\n\t\t# Ensure hidden_dim is divisible by num_heads\n\t\tif hidden_dim % num_heads != 0:\n\t\t\traise ValueError(f\"hidden_dim ({hidden_dim}) must be divisible by num_heads ({num_heads})\")\n\n\t\t# Linear projections for Query, Key, Value\n\t\tself.query_proj = nn.Linear(hidden_dim, hidden_dim)\n\t\tself.key_proj = nn.Linear(hidden_dim, hidden_dim)\n\t\tself.value_proj = nn.Linear(hidden_dim, hidden_dim)\n\t\t\n\t\t# Output projection\n\t\tself.output_proj = nn.Linear(hidden_dim, hidden_dim)\n\t\t\n\t\t# Scaling factor for numerical stability\n\t\tself.scale = (self.head_dim) ** -0.5\n\n\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n\t\t\"\"\"\n\t\tApply attention-based pooling to sequence.\n\t\t\n\t\tArgs:\n\t\t\tx: Input tensor of shape (batch_size, seq_len, hidden_dim)\n\t\t\n\t\tReturns:\n\t\t\tPooled representation of shape (batch_size, hidden_dim)\n\t\t\"\"\"\n\t\tbatch_size = x.size(0)\n\t\tseq_len = x.size(1)\n\n\t\t# Project to Q, K, V: (batch, seq_len, hidden_dim)\n\t\tQ = self.query_proj(x)\n\t\tK = self.key_proj(x)\n\t\tV = self.value_proj(x)\n\n\t\t# Reshape for multi-head attention\n\t\t# (batch, seq_len, hidden_dim) -> (batch, seq_len, num_heads, head_dim)\n\t\tQ = Q.view(batch_size, seq_len, self.num_heads, self.head_dim)\n\t\tK = K.view(batch_size, seq_len, self.num_heads, self.head_dim)\n\t\tV = V.view(batch_size, seq_len, self.num_heads, self.head_dim)\n\n\t\t# Transpose for attention computation\n\t\t# (batch, seq_len, num_heads, head_dim) -> (batch, num_heads, seq_len, head_dim)\n\t\tQ = Q.transpose(1, 2)\n\t\tK = K.transpose(1, 2)\n\t\tV = V.transpose(1, 2)\n\n\t\t# Compute attention scores: Q @ K^T / sqrt(d_k)\n\t\t# (batch, num_heads, seq_len, seq_len)\n\t\tscores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale\n\n\t\t# Apply softmax to get attention weights\n\t\tattention_weights = F.softmax(scores, dim=-1)\n\n\t\t# Apply attention to values\n\t\t# (batch, num_heads, seq_len, head_dim)\n\t\tcontext = torch.matmul(attention_weights, V)\n\n\t\t# Concatenate heads: (batch, seq_len, hidden_dim)\n\t\tcontext = context.transpose(1, 2).contiguous()\n\t\tcontext = context.view(batch_size, seq_len, self.hidden_dim)\n\n\t\t# Final output projection\n\t\toutput = self.output_proj(context)\n\n\t\t# Pool across sequence dimension: take mean over all positions\n\t\t# This produces a fixed-size representation: (batch, hidden_dim)\n\t\tpooled = output.mean(dim=1)\n\n\t\treturn pooled\n\n\n# ============================================================================\n# Model: CNN -> BiLSTM -> Attention Pooling -> FC\n# ============================================================================\n\n\nclass RNABindingCNNBiLSTM(nn.Module):\n\t\"\"\"Detect local motifs with CNN then model context with BiLSTM and attention pooling.\"\"\"\n\n\tdef __init__(\n\t\tself,\n\t\tnum_filters: int = 64,\n\t\tkernel_size: int = 8,\n\t\tlstm_hidden: int = 64,\n\t\tlstm_layers: int = 1,\n\t\tdropout_rate: float = 0.3,\n\t\tnum_attention_heads: int = 2,\n\t\tinput_channels: int = 4,\n\t\tseq_length: int = 41,\n\t):\n\t\tsuper().__init__()\n\n\t\tself.seq_length = seq_length\n\t\tself.num_directions = 2  # bidirectional\n\t\tself.lstm_layers = lstm_layers\n\t\tself.lstm_hidden = lstm_hidden\n\n\t\t# Motif detector\n\t\tself.conv1 = nn.Conv1d(\n\t\t\tin_channels=input_channels,\n\t\t\tout_channels=num_filters,\n\t\t\tkernel_size=kernel_size,\n\t\t\tstride=1,\n\t\t\tpadding=kernel_size // 2,\n\t\t)\n\n\t\t# Batch Normalization after convolution for better regularization\n\t\tself.bn1 = nn.BatchNorm1d(num_filters)\n\n\t\tself.dropout_conv = nn.Dropout(dropout_rate * 0.5)\n\n\t\t# Context encoder\n\t\tself.lstm = nn.LSTM(\n\t\t\tinput_size=num_filters,\n\t\t\thidden_size=lstm_hidden,\n\t\t\tnum_layers=lstm_layers,\n\t\t\tbatch_first=True,\n\t\t\tbidirectional=True,\n\t\t)\n\n\t\t# Attention-based pooling layer\n\t\t# Takes all BiLSTM outputs and produces a weighted aggregation\n\t\tlstm_output_dim = lstm_hidden * self.num_directions\n\t\tself.attention_pool = AttentionPooling(\n\t\t\thidden_dim=lstm_output_dim,\n\t\t\tnum_heads=num_attention_heads\n\t\t)\n\n\t\t# FC head\n\t\tfc_in = lstm_output_dim\n\t\tself.fc1 = nn.Linear(fc_in, 128)\n\t\tself.bn_fc1 = nn.BatchNorm1d(128)\n\t\tself.fc2 = nn.Linear(128, 64)\n\t\tself.bn_fc2 = nn.BatchNorm1d(64)\n\t\tself.fc3 = nn.Linear(64, 1)\n\n\t\tself.dropout = nn.Dropout(dropout_rate)\n\n\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n\t\t\"\"\"\n\t\tForward pass through the network.\n\t\t\n\t\tPipeline:\n\t\t  1. CNN: Extract local motif features\n\t\t  2. BiLSTM: Model sequential context (forward & backward)\n\t\t  3. Attention Pooling: Learn which positions matter most\n\t\t  4. FC Layers: Map to binding affinity prediction\n\t\t\"\"\"\n\t\t# x: (batch, seq_len, 4)\n\t\tx = x.transpose(1, 2)  # -> (batch, 4, seq_len)\n\t\tx = self.conv1(x)\n\t\tx = self.bn1(x)\n\t\tx = F.relu(x)  # -> (batch, filters, seq_len)\n\t\tx = self.dropout_conv(x)\n\n\t\t# Prepare for LSTM\n\t\tx = x.transpose(1, 2)  # -> (batch, seq_len, filters)\n\t\tlstm_out, (h_n, _) = self.lstm(x)  # lstm_out: (batch, seq_len, 2*lstm_hidden)\n\n\t\t# Apply attention-based pooling to aggregate across sequence positions\n\t\t# lstm_out: (batch, seq_len, 2*lstm_hidden)\n\t\t# -> (batch, 2*lstm_hidden)\n\t\tcontextual = self.attention_pool(lstm_out)\n\n\t\t# Pass through fully connected head\n\t\tx = self.fc1(contextual)\n\t\tx = self.bn_fc1(x)\n\t\tx = F.relu(x)\n\t\tx = self.dropout(x)\n\n\t\tx = self.fc2(x)\n\t\tx = self.bn_fc2(x)\n\t\tx = F.relu(x)\n\t\tx = self.dropout(x)\n\n\t\tx = self.fc3(x)\n\t\treturn x\n\n\n# ============================================================================\n# Training / evaluation helpers\n# ============================================================================\n\n\ndef train_epoch(\n\tmodel: nn.Module,\n\ttrain_loader: DataLoader,\n\toptimizer: optim.Optimizer,\n\tdevice: torch.device,\n) -> Tuple[float, float]:\n\tmodel.train()\n\ttotal_loss = 0.0\n\ttotal_corr = 0.0\n\tnum_batches = 0\n\n\tfor batch_idx, (sequences, targets, masks) in enumerate(train_loader):\n\t\tsequences = sequences.to(device)\n\t\ttargets = targets.to(device)\n\t\tmasks = masks.to(device)\n\n\t\toptimizer.zero_grad()\n\n\t\tpredictions = model(sequences)\n\t\tloss = masked_mse_loss(predictions, targets, masks)\n\t\tloss.backward()\n\t\toptimizer.step()\n\n\t\twith torch.no_grad():\n\t\t\tcorr = masked_spearman_correlation(predictions, targets, masks)\n\n\t\ttotal_loss += loss.item()\n\t\ttotal_corr += corr.item()\n\t\tnum_batches += 1\n\n\t\t# if (batch_idx + 1) % 50 == 0:\n\t\t# \tprint(\n\t\t# \t\tf\"  Batch {batch_idx + 1}/{len(train_loader)}: \"\n\t\t# \t\tf\"Loss = {loss.item():.4f}, Corr = {corr.item():.4f}\"\n\t\t# \t)\n\n\tavg_loss = total_loss / num_batches\n\tavg_corr = total_corr / num_batches\n\treturn avg_loss, avg_corr\n\n\ndef evaluate(\n\tmodel: nn.Module,\n\tdata_loader: DataLoader,\n\tdevice: torch.device,\n) -> Tuple[float, float]:\n\tmodel.eval()\n\ttotal_loss = 0.0\n\ttotal_corr = 0.0\n\tnum_batches = 0\n\n\twith torch.no_grad():\n\t\tfor sequences, targets, masks in data_loader:\n\t\t\tsequences = sequences.to(device)\n\t\t\ttargets = targets.to(device)\n\t\t\tmasks = masks.to(device)\n\n\t\t\tpredictions = model(sequences)\n\t\t\tloss = masked_mse_loss(predictions, targets, masks)\n\t\t\tcorr = masked_spearman_correlation(predictions, targets, masks)\n\n\t\t\ttotal_loss += loss.item()\n\t\t\ttotal_corr += corr.item()\n\t\t\tnum_batches += 1\n\n\tavg_loss = total_loss / num_batches\n\tavg_corr = total_corr / num_batches\n\treturn avg_loss, avg_corr\n\n\ndef train_model(\n\tmodel: nn.Module,\n\ttrain_loader: DataLoader,\n\tval_loader: DataLoader,\n\tnum_epochs: int,\n\tlearning_rate: float,\n\tdevice: torch.device,\n\tsave_path: Optional[str] = None,\n\tweight_decay: float = 1e-3,\n\tearly_stopping_patience: int = 5\n) -> Dict[str, List[float]]:\n\tstart_time = time.time()\n\n\tprint(f\"\\n{'='*70}\")\n\tprint(f\"Starting Training on {device}\")\n\tprint(f\"{'='*70}\")\n\tprint(f\"Regularization: Weight Decay = {weight_decay}, Early Stopping Patience = {early_stopping_patience}\")\n\n\toptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\n\n\thistory: Dict[str, List[float]] = {\n\t\t\"train_loss\": [],\n\t\t\"train_corr\": [],\n\t\t\"val_loss\": [],\n\t\t\"val_corr\": [],\n\t}\n\n\tbest_val_corr = -1.0\n\tpatience_counter = 0\n\n\tfor epoch in range(num_epochs):\n\t\tprint(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n\t\tprint(f\"{'-'*70}\")\n\n\t\ttrain_loss, train_corr = train_epoch(model, train_loader, optimizer, device)\n\t\tval_loss, val_corr = evaluate(model, val_loader, device)\n\n\t\thistory[\"train_loss\"].append(train_loss)\n\t\thistory[\"train_corr\"].append(train_corr)\n\t\thistory[\"val_loss\"].append(val_loss)\n\t\thistory[\"val_corr\"].append(val_corr)\n\n\t\tprint(\n\t\t\tf\"\\nEpoch {epoch + 1} Summary:\\n\"\n\t\t\tf\"  Train Loss: {train_loss:.4f} | Train Corr: {train_corr:.4f}\\n\"\n\t\t\tf\"  Val Loss:   {val_loss:.4f} | Val Corr:   {val_corr:.4f}\"\n\t\t)\n\n\t\tif val_corr > best_val_corr:\n\t\t\tbest_val_corr = val_corr\n\t\t\tpatience_counter = 0\n\t\t\tif save_path:\n\t\t\t\ttorch.save(\n\t\t\t\t\t{\n\t\t\t\t\t\t\"epoch\": epoch,\n\t\t\t\t\t\t\"model_state_dict\": model.state_dict(),\n\t\t\t\t\t\t\"optimizer_state_dict\": optimizer.state_dict(),\n\t\t\t\t\t\t\"val_corr\": val_corr,\n\t\t\t\t\t},\n\t\t\t\t\tsave_path,\n\t\t\t\t)\n\t\t\t\tprint(f\"  >>> New best model saved! (Val Corr: {val_corr:.4f})\")\n\t\telse:\n\t\t\tpatience_counter += 1\n\t\t\tprint(f\"  No improvement. Patience: {patience_counter}/{early_stopping_patience}\")\n\t\t\tif patience_counter >= early_stopping_patience:\n\t\t\t\tprint(f\"\\n{'='*70}\")\n\t\t\t\tprint(f\"Early stopping triggered after {epoch + 1} epochs\")\n\t\t\t\tprint(f\"{'='*70}\\n\")\n\t\t\t\tbreak\n\n\telapsed_time = time.time() - start_time\n\n\tprint(f\"\\n{'='*70}\")\n\tprint(f\"Training Complete! Best Val Correlation: {best_val_corr:.4f}\")\n\tprint(f\"Total Training Time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n\tprint(f\"{'='*70}\\n\")\n\n\thistory['elapsed_time'] = elapsed_time\n\treturn history\n\n\n# ============================================================================\n# Hyperparameter search (small, curated)\n# ============================================================================\n\n\ndef hyperparameter_search(\n\tprotein_name: str,\n\tconfig: RNAConfig,\n\tdevice: torch.device,\n\tbatch_size: int = 64,\n\tnum_epochs: int = 15,\n) -> Tuple[Dict, List[Dict]]:\n\tprint(f\"\\n{'='*70}\")\n\tprint(f\"HYPERPARAMETER SEARCH FOR {protein_name}\")\n\tprint(f\"{'='*70}\\n\")\n\n\tprint(\"Loading data (this will take a minute or two)...\")\n\tloader = RNACompeteLoader(config)\n\ttrain_dataset = loader.get_data(protein_name, split=\"train\")\n\tval_dataset = loader.get_data(protein_name, split=\"val\")\n\n\ttrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\tval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\t\n\t#test_configs for different number of attention heads:\n\ttest_configs = [\n\t\t{\"num_filters\": 96, \"kernel_size\": 8, \"lstm_hidden\": 128, \"lstm_layers\": 1, \"dropout_rate\": 0.5, \"num_attention_heads\": h, \"learning_rate\": 5e-4}\n\t\tfor h in [1, 2, 4, 8]\n\t]\n\n\tbest_config: Optional[Dict] = None\n\tbest_val_corr = -1.0\n\tall_results: List[Dict] = []\n\n\tfor idx, params in enumerate(test_configs):\n\t\tprint(f\"\\n{'='*70}\")\n\t\tprint(f\"Configuration {idx + 1}/{len(test_configs)}\")\n\t\tprint(f\"{'='*70}\")\n\t\tprint(f\"Parameters: {params}\")\n\n\t\tmodel = RNABindingCNNBiLSTM(\n\t\t\tnum_filters=params[\"num_filters\"],\n\t\t\tkernel_size=params[\"kernel_size\"],\n\t\t\tlstm_hidden=params[\"lstm_hidden\"],\n\t\t\tlstm_layers=params[\"lstm_layers\"],\n\t\t\tdropout_rate=params[\"dropout_rate\"],\n\t\t\tnum_attention_heads=params[\"num_attention_heads\"],\n\t\t).to(device)\n\n\t\thistory = train_model(\n\t\t\tmodel=model,\n\t\t\ttrain_loader=train_loader,\n\t\t\tval_loader=val_loader,\n\t\t\tnum_epochs=num_epochs,\n\t\t\tlearning_rate=params[\"learning_rate\"],\n\t\t\tdevice=device,\n\t\t\tsave_path=None,\n\t\t)\n\n\t\tfinal_val_corr = history[\"val_corr\"][-1]\n\t\tall_results.append({\"params\": params, \"final_val_corr\": final_val_corr})\n\n\t\tif final_val_corr > best_val_corr:\n\t\t\tbest_val_corr = final_val_corr\n\t\t\tbest_config = params.copy()\n\t\t\tprint(f\"\\n>>> NEW BEST CONFIGURATION! Val Corr: {final_val_corr:.4f}\")\n\n\tprint(f\"\\n{'='*70}\")\n\tprint(\"HYPERPARAMETER SEARCH COMPLETE\")\n\tprint(f\"{'='*70}\\n\")\n\tprint(\"Best Configuration:\")\n\tfor k, v in best_config.items():\n\t\tprint(f\"  {k}: {v}\")\n\tprint(f\"\\nBest Validation Correlation: {best_val_corr:.4f}\")\n\n\treturn best_config, all_results\n\n\n# ============================================================================\n# Data exploration helper\n# ============================================================================\n\n\ndef run_data_exploration(\n\tprotein_name: str,\n\tconfig: RNAConfig,\n\toutput_dir: str = \"results\",\n\tsplits: Tuple[str, ...] = (\"train\", \"val\", \"test\"),\n) -> Dict[str, Dict]:\n\tos.makedirs(output_dir, exist_ok=True)\n\tloader = RNACompeteLoader(config)\n\n\tsummaries: Dict[str, Dict] = {}\n\tfor split in splits:\n\t\tprint(f\"Loading {protein_name} {split} split for exploration...\")\n\t\tdataset = loader.get_data(protein_name, split=split)\n\t\tsummary = dataset_summary(dataset)\n\t\tsummaries[split] = summary\n\n\t\tsummary_path = os.path.join(output_dir, f\"{protein_name}_{split}_summary.json\")\n\t\twith open(summary_path, \"w\") as f:\n\t\t\tjson.dump(summary, f, indent=2)\n\t\tprint(f\"  Saved summary to {summary_path}\")\n\n\treturn summaries\n\n\n# ============================================================================\n# Main\n# ============================================================================\n\n\ndef main():\n\t\"\"\"\n\tparser = argparse.ArgumentParser(description=\"RNAcompete CNN+BiLSTM trainer and data explorer\")\n\tparser.add_argument(\"--protein\", default=\"RBFOX1\", help=\"Protein name to process\")\n\tparser.add_argument(\"--batch-size\", type=int, default=64, help=\"Batch size for training\")\n\tparser.add_argument(\"--epochs\", type=int, default=50, help=\"Number of training epochs\")\n\tparser.add_argument(\"--hyperparam-search\", action=\"store_true\", help=\"Run hyperparameter search instead of default config\")\n\tparser.add_argument(\"--explore-only\", action=\"store_true\", help=\"Only run data summary/plots and skip training\")\n\targs = parser.parse_args()\n\t\"\"\"\n\n\targs = Namespace(protein=\"RBFOX1\", batch_size=64, epochs=50, hyperparam_search=False, explore_only=False)\n\t\n\tconfigure_seed(42)\n\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\tprint(f\"Using device: {device}\")\n\n\tconfig = RNAConfig()\n\tos.makedirs(\"results\", exist_ok=True)\n\tos.makedirs(\"models\", exist_ok=True)\n\n\tif args.explore_only:\n\t\tprint(f\"\\n{'='*70}\")\n\t\tprint(f\"DATA EXPLORATION FOR {args.protein}\")\n\t\tprint(f\"{'='*70}\\n\")\n\t\trun_data_exploration(protein_name=args.protein, config=config, output_dir=\"results\")\n\t\tprint(\"Data exploration finished. Skipping training as requested.\")\n\t\treturn\n\n\tif args.hyperparam_search:\n\t\tbest_config, all_results = hyperparameter_search(\n\t\t\tprotein_name=args.protein,\n\t\t\tconfig=config,\n\t\t\tdevice=device,\n\t\t\tbatch_size=args.batch_size,\n\t\t\tnum_epochs=15,\n\t\t)\n\n\t\tresults_file = f\"results/{args.protein}_hyperparameter_search_bilstm.json\"\n\t\twith open(results_file, \"w\") as f:\n\t\t\tserializable_results = [\n\t\t\t\t{\"params\": res[\"params\"], \"final_val_corr\": res[\"final_val_corr\"]}\n\t\t\t\tfor res in all_results\n\t\t\t]\n\t\t\tjson.dump({\"best_config\": best_config, \"all_results\": serializable_results}, f, indent=2)\n\t\tprint(f\"Hyperparameter search results saved to {results_file}\")\n\n\telse:\n\t\tbest_config = {\n\t\t\t\"num_filters\": 64,\n\t\t\t\"kernel_size\": 8,\n\t\t\t\"lstm_hidden\": 64,\n\t\t\t\"lstm_layers\": 1,\n\t\t\t\"dropout_rate\": 0.3,\n\t\t\t\"num_attention_heads\": 1,\n\t\t\t\"learning_rate\": 1e-3,\n\t\t}\n\t\tprint(\"\\nUsing default configuration:\")\n\t\tfor key, value in best_config.items():\n\t\t\tprint(f\"  {key}: {value}\")\n\n\tprint(f\"\\n{'='*70}\")\n\tprint(f\"TRAINING FINAL MODEL FOR {args.protein}\")\n\tprint(f\"{'='*70}\\n\")\n\n\tprint(\"Loading data (this will take a minute or two)...\")\n\tloader = RNACompeteLoader(config)\n\ttrain_dataset = loader.get_data(args.protein, split=\"train\")\n\tval_dataset = loader.get_data(args.protein, split=\"val\")\n\ttest_dataset = loader.get_data(args.protein, split=\"test\")\n\n\ttrain_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n\tval_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n\ttest_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n\n\tprint(f\"Train set: {len(train_dataset)} samples\")\n\tprint(f\"Val set:   {len(val_dataset)} samples\")\n\tprint(f\"Test set:  {len(test_dataset)} samples\")\n\n\tmodel = RNABindingCNNBiLSTM(\n\t\tnum_filters=best_config[\"num_filters\"],\n\t\tkernel_size=best_config[\"kernel_size\"],\n\t\tlstm_hidden=best_config[\"lstm_hidden\"],\n\t\tlstm_layers=best_config[\"lstm_layers\"],\n\t\tdropout_rate=best_config[\"dropout_rate\"],\n\t\tnum_attention_heads=best_config[\"num_attention_heads\"],\n\t).to(device)\n\n\tprint(\"\\nModel Architecture:\")\n\tprint(model)\n\tprint(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\n\tmodel_save_path = f\"models/{args.protein}_best_model_bilstm.pt\"\n\thistory = train_model(\n\t\tmodel=model,\n\t\ttrain_loader=train_loader,\n\t\tval_loader=val_loader,\n\t\tnum_epochs=args.epochs,\n\t\tlearning_rate=best_config[\"learning_rate\"],\n\t\tdevice=device,\n\t\tsave_path=model_save_path,\n\t)\n\n\tprint(f\"\\n{'='*70}\")\n\tprint(\"FINAL EVALUATION ON TEST SET\")\n\tprint(f\"{'='*70}\\n\")\n\n\tcheckpoint = torch.load(model_save_path, weights_only=True)\n\tmodel.load_state_dict(checkpoint[\"model_state_dict\"])\n\n\ttest_loss, test_corr = evaluate(model, test_loader, device)\n\n\tprint(f\"Test Loss:        {test_loss:.4f}\")\n\tprint(f\"Test Correlation: {test_corr:.4f}\")\n\n\tfinal_results = {\n\t\t\"protein\": args.protein,\n\t\t\"config\": best_config,\n\t\t\"test_loss\": test_loss,\n\t\t\"test_correlation\": test_corr,\n\t\t\"training_time_seconds\": history['elapsed_time'],\n\t\t\"training_time_minutes\": history['elapsed_time'] / 60,\n\t\t\"history\": {k: ([float(v) for v in vals] if isinstance(vals, list) else float(vals)) for k, vals in history.items()}\n    }\n\n\tresults_file = f\"results/{args.protein}_final_results_bilstm.json\"\n\twith open(results_file, \"w\") as f:\n\t\tjson.dump(final_results, f, indent=2)\n\tprint(f\"\\nResults saved to {results_file}\")\n\n\tactual_epochs = len(history['train_loss'])\n\tepochs = list(range(1, actual_epochs + 1))\n\n\tplot(\n\t\tepochs=epochs,\n\t\tplottables={\"Train Loss\": history[\"train_loss\"], \"Val Loss\": history[\"val_loss\"]},\n\t\tfilename=f\"results/{args.protein}_loss_curve_bilstm.png\",\n\t)\n\tprint(f\"Loss curve saved to results/{args.protein}_loss_curve_bilstm.png\")\n\n\tplot(\n\t\tepochs=epochs,\n\t\tplottables={\"Train Correlation\": history[\"train_corr\"], \"Val Correlation\": history[\"val_corr\"]},\n\t\tfilename=f\"results/{args.protein}_correlation_curve_bilstm.png\",\n\t\tylim=[0, 1],\n\t)\n\tprint(f\"Correlation curve saved to results/{args.protein}_correlation_curve_bilstm.png\")\n\n\tprint(f\"\\n{'='*70}\")\n\tprint(\"ALL DONE!\")\n\tprint(f\"{'='*70}\\n\")\n\n\nif __name__ == \"__main__\":\n\tmain()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T23:16:32.072400Z","iopub.execute_input":"2026-01-08T23:16:32.072915Z","iopub.status.idle":"2026-01-08T23:20:21.230545Z","shell.execute_reply.started":"2026-01-08T23:16:32.072876Z","shell.execute_reply":"2026-01-08T23:20:21.229655Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n\nUsing default configuration:\n  num_filters: 64\n  kernel_size: 8\n  lstm_hidden: 64\n  lstm_layers: 1\n  dropout_rate: 0.3\n  num_attention_heads: 1\n  learning_rate: 0.001\n\n======================================================================\nTRAINING FINAL MODEL FOR RBFOX1\n======================================================================\n\nLoading data (this will take a minute or two)...\nFound preprocessed data at /kaggle/input/rnacompete-dt/RBFOX1_train_data.pt. Loading...\nFound preprocessed data at /kaggle/input/rnacompete-dt/RBFOX1_val_data.pt. Loading...\nFound preprocessed data at /kaggle/input/rnacompete-dt/RBFOX1_test_data.pt. Loading...\nTrain set: 96261 samples\nVal set:   24065 samples\nTest set:  121031 samples\n\nModel Architecture:\nRNABindingCNNBiLSTM(\n  (conv1): Conv1d(4, 64, kernel_size=(8,), stride=(1,), padding=(4,))\n  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout_conv): Dropout(p=0.15, inplace=False)\n  (lstm): LSTM(64, 64, batch_first=True, bidirectional=True)\n  (attention_pool): AttentionPooling(\n    (query_proj): Linear(in_features=128, out_features=128, bias=True)\n    (key_proj): Linear(in_features=128, out_features=128, bias=True)\n    (value_proj): Linear(in_features=128, out_features=128, bias=True)\n    (output_proj): Linear(in_features=128, out_features=128, bias=True)\n  )\n  (fc1): Linear(in_features=128, out_features=128, bias=True)\n  (bn_fc1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc2): Linear(in_features=128, out_features=64, bias=True)\n  (bn_fc2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc3): Linear(in_features=64, out_features=1, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n)\n\nTotal parameters: 160,065\n\n======================================================================\nStarting Training on cuda\n======================================================================\nRegularization: Weight Decay = 0.001, Early Stopping Patience = 5\n\nEpoch 1/50\n----------------------------------------------------------------------\n\nEpoch 1 Summary:\n  Train Loss: 0.6170 | Train Corr: 0.4587\n  Val Loss:   0.4823 | Val Corr:   0.5293\n  >>> New best model saved! (Val Corr: 0.5293)\n\nEpoch 2/50\n----------------------------------------------------------------------\n\nEpoch 2 Summary:\n  Train Loss: 0.5078 | Train Corr: 0.5273\n  Val Loss:   0.4992 | Val Corr:   0.4646\n  No improvement. Patience: 1/5\n\nEpoch 3/50\n----------------------------------------------------------------------\n\nEpoch 3 Summary:\n  Train Loss: 0.4763 | Train Corr: 0.5513\n  Val Loss:   0.4282 | Val Corr:   0.5777\n  >>> New best model saved! (Val Corr: 0.5777)\n\nEpoch 4/50\n----------------------------------------------------------------------\n\nEpoch 4 Summary:\n  Train Loss: 0.4571 | Train Corr: 0.5673\n  Val Loss:   0.4366 | Val Corr:   0.5338\n  No improvement. Patience: 1/5\n\nEpoch 5/50\n----------------------------------------------------------------------\n\nEpoch 5 Summary:\n  Train Loss: 0.4423 | Train Corr: 0.5761\n  Val Loss:   0.4596 | Val Corr:   0.5876\n  >>> New best model saved! (Val Corr: 0.5876)\n\nEpoch 6/50\n----------------------------------------------------------------------\n\nEpoch 6 Summary:\n  Train Loss: 0.4311 | Train Corr: 0.5843\n  Val Loss:   0.4254 | Val Corr:   0.5744\n  No improvement. Patience: 1/5\n\nEpoch 7/50\n----------------------------------------------------------------------\n\nEpoch 7 Summary:\n  Train Loss: 0.4221 | Train Corr: 0.5888\n  Val Loss:   0.3994 | Val Corr:   0.6066\n  >>> New best model saved! (Val Corr: 0.6066)\n\nEpoch 8/50\n----------------------------------------------------------------------\n\nEpoch 8 Summary:\n  Train Loss: 0.4172 | Train Corr: 0.5906\n  Val Loss:   0.4430 | Val Corr:   0.6076\n  >>> New best model saved! (Val Corr: 0.6076)\n\nEpoch 9/50\n----------------------------------------------------------------------\n\nEpoch 9 Summary:\n  Train Loss: 0.4151 | Train Corr: 0.5903\n  Val Loss:   0.4646 | Val Corr:   0.6096\n  >>> New best model saved! (Val Corr: 0.6096)\n\nEpoch 10/50\n----------------------------------------------------------------------\n\nEpoch 10 Summary:\n  Train Loss: 0.4160 | Train Corr: 0.5894\n  Val Loss:   0.3952 | Val Corr:   0.5923\n  No improvement. Patience: 1/5\n\nEpoch 11/50\n----------------------------------------------------------------------\n\nEpoch 11 Summary:\n  Train Loss: 0.4075 | Train Corr: 0.5943\n  Val Loss:   0.4539 | Val Corr:   0.5996\n  No improvement. Patience: 2/5\n\nEpoch 12/50\n----------------------------------------------------------------------\n\nEpoch 12 Summary:\n  Train Loss: 0.4111 | Train Corr: 0.5929\n  Val Loss:   0.4248 | Val Corr:   0.6231\n  >>> New best model saved! (Val Corr: 0.6231)\n\nEpoch 13/50\n----------------------------------------------------------------------\n\nEpoch 13 Summary:\n  Train Loss: 0.4030 | Train Corr: 0.5960\n  Val Loss:   0.4276 | Val Corr:   0.6169\n  No improvement. Patience: 1/5\n\nEpoch 14/50\n----------------------------------------------------------------------\n\nEpoch 14 Summary:\n  Train Loss: 0.4054 | Train Corr: 0.5920\n  Val Loss:   0.3948 | Val Corr:   0.6117\n  No improvement. Patience: 2/5\n\nEpoch 15/50\n----------------------------------------------------------------------\n\nEpoch 15 Summary:\n  Train Loss: 0.4032 | Train Corr: 0.5946\n  Val Loss:   0.3829 | Val Corr:   0.6130\n  No improvement. Patience: 3/5\n\nEpoch 16/50\n----------------------------------------------------------------------\n\nEpoch 16 Summary:\n  Train Loss: 0.4004 | Train Corr: 0.5954\n  Val Loss:   0.3821 | Val Corr:   0.6132\n  No improvement. Patience: 4/5\n\nEpoch 17/50\n----------------------------------------------------------------------\n\nEpoch 17 Summary:\n  Train Loss: 0.3990 | Train Corr: 0.5953\n  Val Loss:   0.4682 | Val Corr:   0.5982\n  No improvement. Patience: 5/5\n\n======================================================================\nEarly stopping triggered after 17 epochs\n======================================================================\n\n\n======================================================================\nTraining Complete! Best Val Correlation: 0.6231\nTotal Training Time: 222.87 seconds (3.71 minutes)\n======================================================================\n\n\n======================================================================\nFINAL EVALUATION ON TEST SET\n======================================================================\n\nTest Loss:        0.4225\nTest Correlation: 0.6273\n\nResults saved to results/RBFOX1_final_results_bilstm.json\nLoss curve saved to results/RBFOX1_loss_curve_bilstm.png\nCorrelation curve saved to results/RBFOX1_correlation_curve_bilstm.png\n\n======================================================================\nALL DONE!\n======================================================================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":8}]}